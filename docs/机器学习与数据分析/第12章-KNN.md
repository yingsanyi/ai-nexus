è¿™æ˜¯ç®—æ³•è¿›é˜¶çš„ç¬¬ä¸€ç«™ã€‚

æˆ‘ä»¬è¦å­¦ä¹ ä¸€ä¸ª**â€œä¸ä»…ç®€å•ï¼Œè€Œä¸”æ·±åˆ»â€**çš„ç®—æ³•â€”â€”**K-è¿‘é‚»ç®—æ³• (K-Nearest Neighbors, ç®€ç§° KNN)**ã€‚

å®ƒæ²¡æœ‰å¤æ‚çš„æ–¹ç¨‹ ï¼Œä¹Ÿæ²¡æœ‰éš¾æ‡‚çš„æ¦‚ç‡å…¬å¼ã€‚å®ƒåªç›¸ä¿¡ä¸€ç‚¹ï¼š**ç‰©ä»¥ç±»èšï¼Œäººä»¥ç¾¤åˆ†**ã€‚

---

# ç¬¬ 12 ç« ï¼šå‡ ä½•ç›´è§‰ â€”â€” K-è¿‘é‚»ç®—æ³• (KNN)

## 12.1 æ ¸å¿ƒæ€æƒ³ï¼šè¿‘æœ±è€…èµ¤ï¼Œè¿‘å¢¨è€…é»‘

KNN çš„é€»è¾‘éå¸¸ç¬¦åˆäººç±»ç›´è§‰ã€‚
å‡è®¾ä½ èµ°è¿›ä¸€ä¸ªé™Œç”Ÿæ´¾å¯¹ï¼Œä¸çŸ¥é“è‡ªå·±å±äºå“ªä¸ªåœˆå­ï¼ˆæ˜¯â€œæå®¢åœˆâ€è¿˜æ˜¯â€œè¿åŠ¨åœˆâ€ï¼‰ã€‚
ä½ è¯¥æ€ä¹ˆåŠï¼Ÿ
**ä½ çœ‹ç¦»ä½ æœ€è¿‘çš„å‡ ä¸ªäººæ˜¯è°ã€‚**

* å¦‚æœç¦»ä½ æœ€è¿‘çš„ 5 ä¸ªäººé‡Œï¼Œæœ‰ 4 ä¸ªåœ¨èŠä»£ç ï¼Œ1 ä¸ªåœ¨èŠè¶³çƒã€‚
* ç»“è®ºï¼šä½ å¤§æ¦‚ç‡å±äºâ€œæå®¢åœˆâ€ã€‚

è¿™å°±æ˜¯ KNN çš„å…¨éƒ¨å¥¥ä¹‰ï¼š**ä¸éœ€è¦è®­ç»ƒï¼ˆæ­»è®°ç¡¬èƒŒï¼‰ï¼Œæ–°æ•°æ®æ¥äº†ï¼Œç›´æ¥æ‰¾ç¦»å®ƒæœ€è¿‘çš„  ä¸ªé‚»å±…æŠ•ç¥¨ã€‚**

---

## 12.2 æ•°å­¦åŸºçŸ³ï¼šæ€ä¹ˆå®šä¹‰â€œè¿‘â€ï¼Ÿ(è·ç¦»å…¬å¼)

åœ¨å‡ ä½•ç©ºé—´é‡Œï¼Œä»€ä¹ˆå«â€œè¿‘â€ï¼Ÿæˆ‘ä»¬éœ€è¦ä¸€æŠŠå°ºå­ã€‚
è™½ç„¶ä½ å¯ä»¥å‡­ç›´è§‰è¯´â€œA ç¦» B å¾ˆè¿‘â€ï¼Œä½†åœ¨æ•°å­¦ä¸Šï¼Œæˆ‘ä»¬éœ€è¦ä¸¥è°¨çš„**è·ç¦»å…¬å¼ (Distance Metric)**ã€‚

å‡è®¾æˆ‘ä»¬æœ‰ä¸¤ä¸ªç‚¹ï¼š

* **ç‚¹ A (ä½ ):** åæ ‡ 
* **ç‚¹ B (é‚»å±…):** åæ ‡ 

### 1. æ¬§æ°è·ç¦» (Euclidean Distance) â€”â€” ç›´å°ºè·ç¦»

è¿™æ˜¯æˆ‘ä»¬åœ¨åˆä¸­å‡ ä½•å­¦è¿‡çš„ï¼Œä¸¤ç‚¹ä¹‹é—´ç›´çº¿æœ€çŸ­ã€‚æœ¬è´¨ä¸Šå°±æ˜¯**å‹¾è‚¡å®šç†**ã€‚

* **é€šä¿—è§£é‡Š:** ä½ æ‹¥æœ‰ä¸€æŠŠèƒ½ç©¿å¢™çš„å°ºå­ï¼Œç›´æ¥æµ‹é‡ä¸¤ç‚¹é—´çš„ç›´çº¿è·ç¦»ã€‚
* **åº”ç”¨:** æœ€å¸¸ç”¨çš„é»˜è®¤è·ç¦»å…¬å¼ã€‚

### 2. æ›¼å“ˆé¡¿è·ç¦» (Manhattan Distance) â€”â€” å‡ºç§Ÿè½¦è·ç¦»

æƒ³è±¡ä½ åœ¨çº½çº¦æ›¼å“ˆé¡¿çš„è¡—å¤´ï¼ˆæˆ–è€…æ˜¯æ£‹ç›˜æ ¼ï¼‰ï¼Œä½ ä¸èƒ½ç©¿å¢™ï¼Œåªèƒ½æ²¿ç€è¡—é“èµ°ç›´è§’ã€‚

* **é€šä¿—è§£é‡Š:** ä½ è¦ä»è·¯å£ A èµ°åˆ°è·¯å£ Bï¼Œå¿…é¡»å…ˆæ¨ªç€èµ°å‡ æ­¥ï¼Œå†ç«–ç€èµ°å‡ æ­¥ã€‚
* **åº”ç”¨:** å½“ç‰¹å¾ç»´åº¦éå¸¸é«˜ï¼Œæˆ–è€…ç‰¹å¾å…·æœ‰æ˜æ˜¾çš„â€œç½‘æ ¼â€å±æ€§æ—¶ä½¿ç”¨ã€‚

---

## 12.3 ç®—æ³•æ­¥éª¤ï¼šKNN çš„â€œä¸‰æ­¥èµ°â€

å½“ä¸€ä¸ªæ–°çš„æ•°æ®ç‚¹ï¼ˆæœªçŸ¥æ ·æœ¬ï¼‰å‡ºç°æ—¶ï¼Œè®¡ç®—æœºæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

1. **ç®—è·ç¦»:** è®¡ç®—è¿™ä¸ªæ–°ç‚¹ä¸æ•°æ®åº“ä¸­**æ‰€æœ‰**å·²çŸ¥ç‚¹çš„è·ç¦»ã€‚
2. **æ‰¾é‚»å±…:** æŒ‰ç…§è·ç¦»æ’åºï¼Œé€‰å‡ºæœ€è¿‘çš„ **** ä¸ªç‚¹ã€‚
3. **åšå†³ç­–:**
* **å¦‚æœæ˜¯åˆ†ç±»ä»»åŠ¡:** è®©è¿™  ä¸ªé‚»å±…**æŠ•ç¥¨**ã€‚è°ç¥¨å¤šï¼Œæˆ‘å°±å±äºè°ã€‚ï¼ˆå°‘æ•°æœä»å¤šæ•°ï¼‰
* **å¦‚æœæ˜¯å›å½’ä»»åŠ¡:** è®¡ç®—è¿™  ä¸ªé‚»å±…çš„**å¹³å‡å€¼**ã€‚



---

## 12.4 å…³é”®å‚æ•°ï¼š å€¼çš„é€‰æ‹©å“²å­¦

 æ˜¯ KNN ä¸­å”¯ä¸€çš„è¶…å‚æ•°ã€‚é€‰å¤§é€‰å°ï¼Œç»“å±€å¤©å·®åœ°åˆ«ã€‚

### æƒ…å†µ Aï¼š å¤ªå° (ä¾‹å¦‚ ) â€”â€” ç‹¬è£è€…

* **é€»è¾‘:** æˆ‘åªçœ‹**æœ€è¿‘çš„ 1 ä¸ª**äººã€‚ä»–æ˜¯ä»€ä¹ˆï¼Œæˆ‘å°±æ˜¯ä»€ä¹ˆã€‚
* **åæœ:** **è¿‡æ‹Ÿåˆ (Overfitting)**ã€‚
* å®¹æ˜“å—åˆ°**å™ªå£° (Noise)** çš„å½±å“ã€‚å¦‚æœç¦»ä½ æœ€è¿‘çš„é‚£ä¸ªäººæ°å¥½æ˜¯ä¸ªâ€œç‰¹ä¾‹â€ï¼ˆæ¯”å¦‚ä¸€ä¸ªæ··è¿›æå®¢åœˆçš„è¶³çƒè¿·ï¼‰ï¼Œä½ å°±è¢«å¸¦æ²Ÿé‡Œå»äº†ã€‚
* å†³ç­–è¾¹ç•Œä¼šå˜å¾—æ”¯ç¦»ç ´ç¢ï¼Œåƒåœ°å›¾ä¸Šçš„é”¯é½¿ã€‚



### æƒ…å†µ Bï¼š å¤ªå¤§ (ä¾‹å¦‚ ) â€”â€” éšå¤§æµ

* **é€»è¾‘:** æˆ‘çœ‹å‘¨å›´ 100 ä¸ªäººã€‚
* **åæœ:** **æ¬ æ‹Ÿåˆ (Underfitting)**ã€‚
* æ— è®ºä½ ç«™åœ¨å“ªé‡Œï¼Œåªè¦å‘¨å›´ 100 ä¸ªäººé‡Œå¤§éƒ¨åˆ†æ˜¯â€œå¤§ä¼—è„¸â€ï¼Œä½ å°±ä¼šè¢«åˆ¤ä¸ºå¤§ä¼—è„¸ã€‚è¾¹ç¼˜ç‰¹å¾è¢«æŠ¹å¹³äº†ã€‚



**âœ… æœ€ä½³å®è·µ:** é€šå¸¸  é€‰ä¸€ä¸ªè¾ƒå°çš„å¥‡æ•°ï¼ˆå¦‚ 3, 5, 7ï¼‰ï¼Œé˜²æ­¢æŠ•ç¥¨å‡ºç°å¹³ç¥¨ã€‚

---

## 12.5 è‡´å‘½é™·é˜±ï¼šç‰¹å¾ç¼©æ”¾ (Feature Scaling)

**è¿™æ˜¯æ–°æ‰‹ 100% ä¼šè¸©çš„å‘ï¼Œè¯·åŠ¡å¿…æ³¨æ„ï¼**

å‡è®¾æˆ‘ä»¬è¦é€šè¿‡â€œèº«é«˜â€å’Œâ€œå·¥èµ„â€æ¥åˆ¤æ–­ä¸€ä¸ªäººæ˜¯å¦å—æ¬¢è¿ï¼š

* **ç‰¹å¾ 1 èº«é«˜:** 1.70 ç±³, 1.80 ç±³... (å·®è·åªæœ‰ 0.1)
* **ç‰¹å¾ 2 å·¥èµ„:** 10000 å…ƒ, 20000 å…ƒ... (å·®è·æ˜¯ 10000)

å¦‚æœæˆ‘ä»¬ç›´æ¥ç®—æ¬§æ°è·ç¦»ï¼š


**åæœ:** è·ç¦»ä¼šè¢«â€œå·¥èµ„â€è¿™ä¸ªå¤§æ•°å­—å®Œå…¨ä¸»å¯¼ï¼Œâ€œèº«é«˜â€çš„å·®å¼‚åœ¨æ•°å­¦ä¸Šå˜å¾—å¾®ä¸è¶³é“ã€‚æ¨¡å‹ä¼šè®¤ä¸ºï¼šå“ªæ€•èº«é«˜å·® 1 ç±³ä¹Ÿæ²¡å…³ç³»ï¼Œåªè¦å·¥èµ„å·® 1 å—é’±å°±æ˜¯è·ç¦»è¿œã€‚

**ğŸ”§ è§£å†³æ–¹æ¡ˆ:** å¿…é¡»ä½¿ç”¨ **æ ‡å‡†åŒ– (StandardScaler)**ï¼ŒæŠŠæ‰€æœ‰ç‰¹å¾æ‹‰åˆ°åŒä¸€ä¸ªé‡çº§ï¼

---

## 12.6 å®æˆ˜æ¡ˆä¾‹ï¼šé¸¢å°¾èŠ±åˆ†ç±» (Iris Dataset)

> **ğŸ¯ ä»»åŠ¡:**
> æˆ‘ä»¬æœ‰ 150 æœµé¸¢å°¾èŠ±çš„æ•°æ®ï¼ŒåŒ…å« 4 ä¸ªç‰¹å¾ï¼ˆèŠ±è¼é•¿ã€èŠ±è¼å®½ã€èŠ±ç“£é•¿ã€èŠ±ç“£å®½ï¼‰ã€‚æˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ª KNNï¼Œå½“æ‹¿åˆ°ä¸€æœµæ–°èŠ±æ—¶ï¼Œåˆ¤æ–­å®ƒæ˜¯å“ªä¸ªå“ç§ã€‚

### Step 1: æ•°æ®å‡†å¤‡ä¸ç¼©æ”¾

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

# 1. åŠ è½½æ•°æ®
iris = load_iris()
X = iris.data
y = iris.target

# 2. åˆ‡åˆ†æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. ğŸ”¥ å…³é”®æ­¥éª¤ï¼šç‰¹å¾ç¼©æ”¾ (æ ‡å‡†åŒ–)
# å¿…é¡»å…ˆåœ¨è®­ç»ƒé›†ä¸Š fitï¼Œå† transform
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # æµ‹è¯•é›†åªèƒ½ transformï¼

print(f"åŸå§‹æ•°æ®ç¤ºä¾‹: {X_train[0]}")
print(f"æ ‡å‡†åŒ–åç¤ºä¾‹: {X_train_scaled[0]}")
# ä½ ä¼šå‘ç°æ ‡å‡†åŒ–åçš„æ•°æ®éƒ½åœ¨ 0 é™„è¿‘

```

### Step 2: è®­ç»ƒä¸é¢„æµ‹

```python
# 4. å®ä¾‹åŒ– KNN æ¨¡å‹
# n_neighbors=5: ä¹Ÿå°±æ˜¯ K=5
knn = KNeighborsClassifier(n_neighbors=5)

# 5. è®­ç»ƒ (å¯¹äº KNN æ¥è¯´ï¼Œè¿™ä¸€æ­¥å…¶å®å°±æ˜¯æŠŠæ•°æ®å­˜è¿›å†…å­˜é‡Œ)
knn.fit(X_train_scaled, y_train)

# 6. é¢„æµ‹
y_pred = knn.predict(X_test_scaled)

# 7. è¯„ä¼°
acc = accuracy_score(y_test, y_pred)
print(f"KNN (K=5) çš„å‡†ç¡®ç‡: {acc:.2%}")

```

### Step 3: å¯»æ‰¾æœ€ä½³çš„ K å€¼

åˆ°åº• K é€‰å‡ æœ€å¥½ï¼Ÿæˆ‘ä»¬å¯ä»¥å†™ä¸ªå¾ªç¯è¯•ä¸€ä¸‹ã€‚

```python
import matplotlib.pyplot as plt

scores = []
k_range = range(1, 20)

for k in k_range:
    # å°è¯•ä¸åŒçš„ K
    curr_knn = KNeighborsClassifier(n_neighbors=k)
    curr_knn.fit(X_train_scaled, y_train)
    scores.append(curr_knn.score(X_test_scaled, y_test))

# ç”»å›¾çœ‹è¶‹åŠ¿
plt.plot(k_range, scores, marker='o')
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.title('Best K for Iris Dataset')
plt.grid()
plt.show()

```

**å›¾è¡¨è§£è¯»:**
ä½ ä¼šçœ‹åˆ°ä¸€ä¸ªè¶‹åŠ¿ï¼š

* K å¾ˆå°æ—¶ï¼Œå‡†ç¡®ç‡å¯èƒ½æ³¢åŠ¨è¾ƒå¤§ã€‚
* K é€‚ä¸­æ—¶ï¼ˆæ¯”å¦‚ 5-10ï¼‰ï¼Œå‡†ç¡®ç‡è¾¾åˆ°é«˜å³°ã€‚
* K å¾ˆå¤§æ—¶ï¼Œå‡†ç¡®ç‡å¯èƒ½ä¼šå¼€å§‹ä¸‹é™ï¼ˆå› ä¸ºå¤ªç¬¼ç»Ÿäº†ï¼‰ã€‚

---

## æœ¬ç« å°ç»“

KNN æ˜¯æ‰€æœ‰ç®—æ³•ä¸­æœ€ç›´è§‚çš„ä¸€ä¸ªï¼š

1. **åŸç†:** åŸºäºå‡ ä½•è·ç¦» (æ¬§æ°è·ç¦»)ã€‚
2. **æ ¸å¿ƒ:** K å€¼çš„é€‰æ‹© (Kå°è¿‡æ‹Ÿåˆï¼ŒKå¤§æ¬ æ‹Ÿåˆ)ã€‚
3. **æ­»ç©´:** **å¿…é¡»åšç‰¹å¾ç¼©æ”¾**ï¼Œä¸”æ•°æ®é‡å¤ªå¤§æ—¶é¢„æµ‹å¾ˆæ…¢ï¼ˆå› ä¸ºè¦ç®—å‡ ç™¾ä¸‡æ¬¡è·ç¦»ï¼‰ã€‚

**ä¸‹ä¸€ç« é¢„å‘Šï¼š**
KNN è™½ç„¶ç®€å•ï¼Œä½†å®ƒæ˜¯ä¸ªâ€œæ–‡ç›²â€ï¼Œå®ƒä¸æ‡‚æ•°æ®çš„é€»è¾‘ï¼ŒåªçŸ¥é“æ¯”è·ç¦»ã€‚
æœ‰æ²¡æœ‰ä¸€ç§ç®—æ³•ï¼Œåƒäººç±»ä¸“å®¶ä¸€æ ·ï¼Œé€šè¿‡ä¸€ç³»åˆ—é€»è¾‘ä¸¥å¯†çš„ **â€œå¦‚æœ...é‚£ä¹ˆ...â€** æ¥è¿›è¡Œæ¨å¯¼ï¼Ÿ
åœ¨ **ç¬¬ 13 ç« **ï¼Œæˆ‘ä»¬å°†å­¦ä¹ è§£é‡Šæ€§æœ€å¼ºçš„ç®—æ³• â€”â€” **å†³ç­–æ ‘ (Decision Tree)**ï¼Œå¹¶ææ‡‚ä»€ä¹ˆæ˜¯â€œä¿¡æ¯ç†µâ€ã€‚