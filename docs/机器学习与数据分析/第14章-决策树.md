è¿™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å…·â€œäººæ€§â€çš„ä¸€ç« ã€‚

ä¹‹å‰çš„ç®—æ³•ï¼ˆKNNã€æœ´ç´ è´å¶æ–¯ã€é€»è¾‘å›å½’ï¼‰éƒ½æœ‰ä¸€ä¸ªå…±åŒçš„ç—›ç‚¹ï¼š**å®ƒä»¬æ˜¯é»‘ç›’**ã€‚

* å½“é“¶è¡Œæ‹’è´·æ—¶ï¼Œç”¨æˆ·é—®ï¼šâ€œä¸ºä»€ä¹ˆæ‹’æˆ‘ï¼Ÿâ€
* é€»è¾‘å›å½’ä¼šè¯´ï¼šâ€œå› ä¸ºä½ çš„å¾—åˆ†æ˜¯ 0.4ï¼Œå°äº 0.5ã€‚â€
* ç”¨æˆ·ï¼šâ€œï¼Ÿï¼Ÿï¼Ÿâ€

è¿™ä¸æ˜¯äººè¯ã€‚
æˆ‘ä»¬éœ€è¦ä¸€ç§ç®—æ³•ï¼Œèƒ½åƒäººç±»ä¸“å®¶ä¸€æ ·ï¼Œç»™å‡ºæ¸…æ™°çš„åˆ¤æ–­é€»è¾‘ï¼š**â€œå› ä¸ºä½ å¹´è–ªä½äº 5 ä¸‡ï¼Œä¸”æ²¡æœ‰æˆ¿äº§æ‹…ä¿ã€‚â€**

è¿™å°±æ˜¯ **å†³ç­–æ ‘ (Decision Tree)** â€”â€” å®ƒæ˜¯å”¯ä¸€èƒ½ç”Ÿæˆ**å¯è§†åŒ–æµç¨‹å›¾**çš„ç®—æ³•ï¼Œä¹Ÿæ˜¯æ‰€è°“çš„â€œç™½ç›’æ¨¡å‹â€ã€‚

---

# ç¬¬ 14 ç« ï¼šè§„åˆ™é€»è¾‘ â€”â€” å†³ç­–æ ‘ (Decision Tree)

## 14.1 æ ¸å¿ƒæ€æƒ³ï¼š20 ä¸ªé—®é¢˜æ¸¸æˆ

å†³ç­–æ ‘çš„é€»è¾‘ï¼Œå…¶å®å°±æ˜¯æˆ‘ä»¬åœ¨ç«¥å¹´ç©è¿‡çš„ **â€œ20 ä¸ªé—®é¢˜â€ (20 Questions)** æˆ–è€… **â€œçŒœäººåâ€** æ¸¸æˆã€‚

**æ¸¸æˆè§„åˆ™ï¼š** æˆ‘å¿ƒé‡Œæƒ³ä¸€ä¸ªäººï¼Œä½ å¯ä»¥é—®æˆ‘â€œæ˜¯/å¦â€çš„é—®é¢˜ï¼Œäº‰å–ç”¨æœ€å°‘çš„é—®é¢˜çŒœå‡ºæ¥ã€‚

* **èœé¸Ÿæé—®:** â€œæ˜¯å‘¨æ°ä¼¦å—ï¼Ÿâ€ â€œæ˜¯æˆé¾™å—ï¼Ÿâ€
* *è¯„ä»·:* æ•ˆç‡æä½ï¼Œå‡ ä¹æ˜¯åœ¨çè’™ã€‚


* **é«˜æ‰‹æé—®:** â€œä»–æ˜¯ç”·çš„å—ï¼Ÿâ€ (æ˜¯) -> â€œä»–æ˜¯æ­Œæ‰‹å—ï¼Ÿâ€ (æ˜¯) -> â€œä»–æ˜¯å¤§é™†çš„å—ï¼Ÿâ€ (å¦)
* *è¯„ä»·:* æ¯ä¸€ä¸ªé—®é¢˜éƒ½æŠŠæœç´¢èŒƒå›´**ç¼©å°äº†ä¸€åŠ**ã€‚



**å†³ç­–æ ‘çš„æœ¬è´¨ï¼š** ç®—æ³•å°±æ˜¯é‚£ä¸ªâ€œé«˜æ‰‹â€ã€‚å®ƒè¯•å›¾æ‰¾åˆ°**æœ€å¥½çš„é—®é¢˜**ï¼ˆç‰¹å¾ï¼‰ï¼ŒæŠŠæ•°æ®åˆ‡åˆ†å¾—è¶Šæ¥è¶Š**çº¯**ã€‚

---

## 14.2 æ•°å­¦æ ¸å¿ƒï¼šä»€ä¹ˆå«â€œå¥½é—®é¢˜â€ï¼Ÿ

æœºå™¨æ€ä¹ˆçŸ¥é“å…ˆé—®â€œæ€§åˆ«â€æ¯”å…ˆé—®â€œæ˜Ÿåº§â€æ›´å¥½ï¼Ÿæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ•°å­¦æŒ‡æ ‡æ¥è¡¡é‡æ•°æ®çš„**â€œçº¯åº¦â€ (Purity)**ã€‚

è¿™é‡Œå¼•å…¥ç‰©ç†å­¦/ä¿¡æ¯è®ºä¸­çš„æ¦‚å¿µï¼š**ç†µ (Entropy)**ã€‚

### 1. æ··ä¹±çš„åº¦é‡ï¼šç†µ (Entropy)

* **ç›´è§‚ç†è§£:**
* å¦‚æœä¸€ä¸ªæˆ¿é—´é‡Œåªæœ‰**çº¢çƒ**ï¼Œæˆ‘ä»¬è¯´å®ƒ**å¾ˆæœ‰åº (çº¯åº¦é«˜)**ï¼Œç†µå¾ˆ**ä½**ã€‚
* å¦‚æœä¸€ä¸ªæˆ¿é—´é‡Œ**çº¢ã€é»„ã€è“çƒ**ä¹±ä¸ƒå…«ç³Ÿæ··åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬è¯´å®ƒ**å¾ˆæ··ä¹± (çº¯åº¦ä½)**ï¼Œç†µå¾ˆ**é«˜**ã€‚


* **æ•°å­¦å…¬å¼:**
é¦™å†œ (Shannon) å®šä¹‰çš„ç†µå…¬å¼å¦‚ä¸‹ï¼š


* : æˆ‘ä»¬çš„æ•°æ®é›†ï¼ˆæ¯”å¦‚ä¸€ä¸ªæˆ¿é—´ï¼‰ã€‚
* : å…±æœ‰å‡ ç±»æ ·æœ¬ï¼ˆæ¯”å¦‚çº¢çƒã€è“çƒï¼Œå°±æ˜¯ 2 ç±»ï¼‰ã€‚
* : ç¬¬  ç±»æ ·æœ¬å‡ºç°çš„**æ¦‚ç‡**ï¼ˆå³å æ¯”ï¼‰ã€‚



> **ğŸ”¢ å°å­¦ç”Ÿéƒ½èƒ½æ‡‚çš„æ‰‹ç®—:**
> å‡è®¾æˆ¿é—´é‡Œæœ‰ 10 ä¸ªçƒã€‚
> **æƒ…å†µ A: 10 ä¸ªå…¨æ˜¯çº¢çƒ (æç«¯çº¯å‡€)**
> * 
> * 
> * **ç»“è®º:** ç†µä¸º 0ï¼Œä»£è¡¨**å®Œå…¨ç¡®å®šçš„ç§©åº**ã€‚
> 
> 
> **æƒ…å†µ B: 5 ä¸ªçº¢çƒï¼Œ5 ä¸ªè“çƒ (æç«¯æ··ä¹±)**
> * 
> * 
> * å› ä¸º 
> * 
> * **ç»“è®º:** ç†µä¸º 1ï¼Œä»£è¡¨**æœ€å¤§çš„ä¸ç¡®å®šæ€§**ï¼ˆä½ éšä¾¿æŠ“ä¸€ä¸ªï¼Œå®Œå…¨çŒœä¸åˆ°é¢œè‰²ï¼‰ã€‚
> 
> 

### 2. ä¿¡æ¯å¢ç›Š (Information Gain) â€”â€” å†³ç­–çš„ä¾æ®

å†³ç­–æ ‘ç”Ÿé•¿çš„è¿‡ç¨‹ï¼Œå°±æ˜¯è¿½æ±‚**â€œä¿¡æ¯å¢ç›Šæœ€å¤§åŒ–â€**ã€‚
é€šä¿—åœ°è¯´ï¼š**é—®å®Œè¿™ä¸ªé—®é¢˜åï¼Œæ··ä¹±ç¨‹åº¦ï¼ˆç†µï¼‰å‡å°‘äº†å¤šå°‘ï¼Ÿ**


*(å¢ç›Š = æ²¡é—®ä¹‹å‰çš„ç†µ - é—®å®Œä¹‹åçš„åŠ æƒå¹³å‡ç†µ)*

> **ğŸ“ é€‰äººå®æˆ˜:**
> å‡è®¾æˆ‘ä»¬è¦é¢„æµ‹â€œè°ä¼šä¹°æ¸¸æˆæœºâ€ï¼Œç°åœ¨æœ‰ 10 ä¸ªäººï¼ˆ5ä¹°ï¼Œ5ä¸ä¹°ï¼‰ï¼Œåˆå§‹ç†µæ˜¯ **1.0**ã€‚
> **é€‰æ‹© 1: æŒ‰â€œæ€§åˆ«â€åˆ‡åˆ†**
> * ç”·ç”Ÿç»„ (6äºº): 5ä¹°ï¼Œ1ä¸ä¹°ã€‚ (éå¸¸çº¯ï¼Œç†µå¾ˆä½ï¼Œå‡è®¾æ˜¯ 0.6)
> * å¥³ç”Ÿç»„ (4äºº): 0ä¹°ï¼Œ4ä¸ä¹°ã€‚ (è¶…çº§çº¯ï¼Œç†µæ˜¯ 0)
> * **åŠ æƒå¹³å‡ç†µ:** 
> * **ä¿¡æ¯å¢ç›Š:**  (æ•ˆæœæ‹”ç¾¤ï¼)
> 
> 
> **é€‰æ‹© 2: æŒ‰â€œçˆ±åƒè¾£â€åˆ‡åˆ†**
> * çˆ±åƒè¾£ (5äºº): 3ä¹°ï¼Œ2ä¸ä¹°ã€‚ (è¿˜æ˜¯ä¹±ï¼Œç†µé«˜)
> * ä¸åƒè¾£ (5äºº): 2ä¹°ï¼Œ3ä¸ä¹°ã€‚ (è¿˜æ˜¯ä¹±ï¼Œç†µé«˜)
> * **åŠ æƒå¹³å‡ç†µ:** 
> * **ä¿¡æ¯å¢ç›Š:**  (å‡ ä¹æ²¡ç”¨)
> 
> 
> **æœºå™¨å†³ç­–:** ï¼Œæ‰€ä»¥æ ¹èŠ‚ç‚¹å¿…é¡»é€‰ **â€œæ€§åˆ«â€**ï¼

### 3. åŸºå°¼ç³»æ•° (Gini Impurity) â€”â€” å¦ä¸€æŠŠå°ºå­

åœ¨ Scikit-Learn ä¸­ï¼Œé»˜è®¤ä½¿ç”¨çš„æ˜¯ **Gini** è€Œä¸æ˜¯ç†µã€‚


* **åŸç†:** å®ƒå’Œç†µçš„æ•ˆæœå‡ ä¹ä¸€æ ·ï¼Œéƒ½æ˜¯è¡¡é‡æ··ä¹±ç¨‹åº¦ã€‚
* **åŒºåˆ«:** Gini ä¸éœ€è¦ç®—å¯¹æ•° ()ï¼Œè®¡ç®—æœºç®—å¹³æ–¹æ¯”ç®—å¯¹æ•°å¿«å¾—å¤šï¼Œæ‰€ä»¥**é€Ÿåº¦æ›´å¿«**ã€‚

---

## 14.3 è‡´å‘½å¼±ç‚¹ï¼šè¿‡æ‹Ÿåˆ (Overfitting)

å†³ç­–æ ‘æœ€å¤§çš„é—®é¢˜åœ¨äºï¼š**å®ƒå¤ªèªæ˜äº†ï¼Œè®°æ€§å¤ªå¥½äº†ã€‚**

å¦‚æœä½ ä¸é™åˆ¶å®ƒï¼Œå®ƒä¼šä¸€ç›´æé—®ï¼Œç›´åˆ°æŠŠæ¯ä¸€ä¸ªå¶å­èŠ‚ç‚¹éƒ½åˆ†åˆ°**åªå‰© 1 ä¸ªæ ·æœ¬**ä¸ºæ­¢ã€‚

* *æ¯”å¦‚:* å®ƒä¸ºäº†åŒºåˆ†ä¸€ä¸ªç‰¹ä¾‹ï¼Œç”Ÿæˆäº†ä¸€æ¡è§„åˆ™ï¼šâ€œå¦‚æœèº«é«˜170 ä¸” ç©¿çº¢è¡£æœ ä¸” æ—©ä¸Šåƒäº†åŒ…å­ -> åäººâ€ã€‚

è¿™å°±åƒä¸€ä¸ªå­¦ç”Ÿ**æ­»è®°ç¡¬èƒŒ**äº†è¯¾æœ¬ä¸Šçš„æ¯ä¸€é“ä¾‹é¢˜ã€‚ä¸€åˆ°æœŸæœ«è€ƒè¯•ï¼ˆæµ‹è¯•é›†ï¼‰é‡åˆ°æ–°é¢˜ï¼Œç›´æ¥æŒ‚ç§‘ã€‚

### ğŸ”§ è§£å†³æ–¹æ¡ˆï¼šå‰ªæ (Pruning)

æˆ‘ä»¬è¦åƒå›­ä¸ä¸€æ ·ï¼Œä¿®å‰ªæ‰é‚£äº›è¿‡äºç¹ççš„æå¶ã€‚

* **é¢„å‰ªæ (Pre-pruning):** åœ¨æ ‘ç”Ÿé•¿ä¹‹å‰å°±å®šå¥½è§„çŸ©ã€‚
* `max_depth`: æ ‘æœ€æ·±åªèƒ½é•¿åˆ° 3 å±‚ã€‚
* `min_samples_leaf`: æ¯ä¸ªå¶å­èŠ‚ç‚¹è‡³å°‘è¦æœ‰ 10 ä¸ªæ ·æœ¬ï¼Œå¦åˆ™ä¸è®¸åˆ†ã€‚



---

## 14.4 å®æˆ˜æ¡ˆä¾‹ï¼šæ³°å¦å°¼å…‹å·çš„å¯è§†åŒ–

æˆ‘ä»¬å†æ¬¡ä½¿ç”¨æ³°å¦å°¼å…‹å·æ•°æ®ï¼Œçœ‹çœ‹å†³ç­–æ ‘èƒ½ä¸èƒ½ç”»å‡ºä¸€å¼ æˆ‘ä»¬èƒ½çœ‹æ‡‚çš„â€œé€ƒç”ŸæŒ‡å—â€ã€‚

### Step 1: è®­ç»ƒæ¨¡å‹

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt
import seaborn as sns

# 1. å‡†å¤‡æ•°æ® (ç®€åŒ–ç‰ˆæ¸…æ´—)
raw_df = sns.load_dataset('titanic')
df = raw_df[['survived', 'pclass', 'sex', 'age', 'fare']].copy()
df['age'].fillna(df['age'].median(), inplace=True)
df = pd.get_dummies(df, columns=['sex'], drop_first=True) # sex_male: 0=å¥³, 1=ç”·

X = df.drop('survived', axis=1)
y = df['survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. è®­ç»ƒå†³ç­–æ ‘
# ğŸ”¥ å…³é”®å‚æ•° max_depth=3: é™åˆ¶æ ‘æ·±åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæ–¹ä¾¿ç”»å›¾
# criterion='entropy': æˆ‘ä»¬å¯ä»¥æ‰‹åŠ¨æŒ‡å®šç”¨â€œç†µâ€æ¥ç®—ï¼Œé»˜è®¤æ˜¯ gini
model = DecisionTreeClassifier(max_depth=3, criterion='entropy')
model.fit(X_train, y_train)

print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {model.score(X_train, y_train):.2%}")
print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {model.score(X_test, y_test):.2%}")

```

### Step 2: ç”»å‡ºâ€œä¸Šå¸è§†è§’â€ (Visualization)

è¿™æ˜¯å†³ç­–æ ‘æœ€é…·çš„åœ°æ–¹ã€‚æˆ‘ä»¬å¯ä»¥æŠŠæ¨¡å‹é€»è¾‘ç”»å‡ºæ¥ã€‚

```python
plt.figure(figsize=(15, 8), dpi=300)

# plot_tree è‡ªåŠ¨ç»˜å›¾
plot_tree(model, 
          feature_names=X.columns,  # ç‰¹å¾åå­—
          class_names=['Dead', 'Survived'], # ç±»åˆ«åå­—
          filled=True, # å¡«å……é¢œè‰² (é¢œè‰²è¶Šæ·±ï¼Œçº¯åº¦è¶Šé«˜)
          rounded=True)

plt.show()

```

**ğŸ‘€ å›¾è¡¨è§£è¯» (ä¸Šå¸æŒ‡å—):**
çœ‹æœ€ä¸Šé¢çš„æ ¹èŠ‚ç‚¹ï¼ˆRoot Nodeï¼‰ï¼š

1. **ç¬¬ä¸€ä¸ªé—®é¢˜:** `sex_male <= 0.5` (å³ï¼šæ˜¯å¥³æ€§å—ï¼Ÿ)
* **True (å·¦è¾¹):** å¤§éƒ¨åˆ†éƒ½æ´»äº†ï¼ˆèƒŒæ™¯æ˜¯è“è‰²ï¼‰ã€‚ç†µè¿…é€Ÿä¸‹é™ï¼
* **False (å³è¾¹):** åªæœ‰å°‘æ•°æ´»äº†ï¼ˆèƒŒæ™¯æ˜¯æ©™è‰²ï¼‰ã€‚


2. **ç¬¬äºŒä¸ªé—®é¢˜ (åœ¨ç”·æ€§è¿™è¾¹):** `age <= 6.5` (æ˜¯å°ç”·å­©å—ï¼Ÿ)
* **True:** å°ç”·å­©ç”Ÿå­˜ç‡è¾ƒé«˜ã€‚
* **False:** æˆå¹´ç”·æ€§ç”Ÿå­˜ç‡æä½ã€‚



**ç»“è®º:** è¿™æ£µæ ‘å®Œç¾å¤ç°äº†â€œå¥³å£«å’Œå°å­©ä¼˜å…ˆâ€çš„è§„åˆ™ï¼Œè€Œä¸”æ˜¯æˆ‘ä»¬è‚‰çœ¼å¯è§çš„é€»è¾‘ï¼

---

## 14.5 ç‰¹å¾é‡è¦æ€§ (Feature Importance)

å†³ç­–æ ‘è¿˜èƒ½å‘Šè¯‰æˆ‘ä»¬ï¼š**å“ªä¸ªç‰¹å¾æœ€é‡è¦ï¼Ÿ**
å®ƒæ˜¯æ ¹æ®ç‰¹å¾åœ¨æ ‘ä¸­å¸¦æ¥çš„**ä¿¡æ¯å¢ç›Šæ€»å’Œ**ç®—å‡ºæ¥çš„ã€‚å¢ç›Šè¶Šå¤§çš„ç‰¹å¾ï¼Œè¶Šé‡è¦ã€‚

```python
import pandas as pd

importances = pd.Series(model.feature_importances_, index=X.columns)
print(importances.sort_values(ascending=False))

```

**è¾“å‡ºç¤ºä¾‹:**

```text
sex_male    0.55  (æ€§åˆ«æœ€é‡è¦ï¼Œå› ä¸ºå®ƒåˆ‡çš„ç¬¬ä¸€åˆ€å¢ç›Šæœ€å¤§)
pclass      0.20  (èˆ±ä½å…¶æ¬¡)
fare        0.15  (ç¥¨ä»·)
age         0.10  (å¹´é¾„)

```

---

## æœ¬ç« å°ç»“

å†³ç­–æ ‘æ˜¯æœºå™¨å­¦ä¹ ä¸­**å¯è§£é‡Šæ€§ (Explainability)** çš„å·…å³°ï¼š

1. **åŸç†:** åŸºäº**ä¿¡æ¯ç†µ (Entropy)** æˆ– **åŸºå°¼ç³»æ•° (Gini)**ï¼Œè´ªå©ªåœ°å¯»æ‰¾å¢ç›Šæœ€å¤§çš„åˆ‡åˆ†ç‚¹ã€‚
2. **ä¼˜ç‚¹:** ç™½ç›’æ¨¡å‹ï¼Œé€»è¾‘æ¸…æ™°ï¼Œèƒ½å¤„ç†éçº¿æ€§æ•°æ®ã€‚
3. **æ­»ç©´:** **æå…¶å®¹æ˜“è¿‡æ‹Ÿåˆ**ï¼ˆå•æ£µæ ‘å¾ˆå®¹æ˜“èµ°æç«¯ï¼‰ã€‚

**ä¸‹ä¸€ç« é¢„å‘Šï¼š**
è™½ç„¶å†³ç­–æ ‘é€»è¾‘æ¸…æ™°ï¼Œä½†ä¸€æ£µæ ‘å®¹æ˜“çŠ¯é”™ï¼ˆè¿‡æ‹Ÿåˆï¼‰ã€‚
å¦‚æœæˆ‘ä»¬åœ¨æ£®æ—é‡Œç§ **100 æ£µæ ‘**ï¼Œæ¯æ£µæ ‘éƒ½æœ‰ä¸€ç‚¹å·®å¼‚ï¼Œç„¶åè®©å®ƒä»¬**æŠ•ç¥¨**å†³å®šç»“æœï¼Œä¼šä¸ä¼šæ›´å‡†ï¼Ÿ
è¿™å°±æ˜¯å·¥ä¸šç•Œæœ€å¼ºå¤§çš„ç®—æ³•å®¶æ— â€”â€” **é›†æˆå­¦ä¹  (Ensemble Learning)**ã€‚
åœ¨ **ç¬¬ 15 ç« **ï¼Œæˆ‘ä»¬å°†å­¦ä¹  **éšæœºæ£®æ— (Random Forest)** å’Œ **XGBoost**ã€‚