è¿™æ˜¯ AI å­¦ä¹ ä¹‹è·¯ä¸Š**é‡Œç¨‹ç¢‘å¼**çš„ä¸€ç« ã€‚

åœ¨å‰å‡ ç« ï¼Œæˆ‘ä»¬åƒé“åŒ ä¸€æ ·æ‰“é€ äº†å…µå™¨ï¼ˆNumPy/Pandasï¼‰ï¼Œå­¦ä¼šäº†ä¾¦å¯Ÿåœ°å½¢ï¼ˆMatplotlib/Seabornï¼‰ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è¦æ­£å¼è¸å…¥æˆ˜åœºï¼ŒæŒ‡æŒ¥æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ª AI å£«å…µâ€”â€”**æœºå™¨å­¦ä¹ æ¨¡å‹**ã€‚

è¿™ä¸€ç« ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Python æœºå™¨å­¦ä¹ é¢†åŸŸçš„ç»å¯¹éœ¸ä¸»ï¼š**Scikit-Learn (sklearn)**ã€‚

---

# ç¬¬ 6 ç« ï¼šä½ å¥½ï¼Œæœºå™¨å­¦ä¹ ï¼šScikit-Learn æç®€å®æˆ˜

**Scikit-Learn (sklearn)** æ˜¯ AI å·¥ç¨‹å¸ˆçš„ç‘å£«å†›åˆ€ã€‚

* å®ƒä¸é€‚åˆåšæ·±å±‚ç¥ç»ç½‘ç»œï¼ˆé‚£æ˜¯ PyTorch çš„åœ°ç›˜ï¼‰ã€‚
* ä½†é™¤æ­¤ä¹‹å¤–çš„**ä¸€åˆ‡**ï¼ˆå›å½’ã€åˆ†ç±»ã€èšç±»ã€é™ç»´ï¼‰ï¼Œå®ƒéƒ½æ˜¯å·¥ä¸šç•Œçš„é¦–é€‰æ ‡å‡†ã€‚

å®ƒçš„ä¼Ÿå¤§ä¹‹å¤„åœ¨äº**â€œç»Ÿä¸€â€**ã€‚æ— è®ºä½ æ˜¯åœ¨åšç®€å•çš„çº¿æ€§å›å½’ï¼Œè¿˜æ˜¯å¤æ‚çš„éšæœºæ£®æ—ï¼Œä»£ç çš„å†™æ³•å‡ ä¹æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚

---

## 6.1 æ ¸å¿ƒå¿ƒæ³•ï¼šScikit-Learn çš„â€œä¸‰æ¿æ–§â€

åœ¨å†™ä»£ç ä¹‹å‰ï¼Œè¯·æŠŠè¿™å¼ æµç¨‹å›¾åˆ»åœ¨è„‘å­é‡Œã€‚Scikit-Learn ä¸­ 99% çš„ç®—æ³•éƒ½éµå¾ªè¿™ä¸ªå¥—è·¯ï¼š

1. **å®ä¾‹åŒ– (Instantiate):** é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ã€‚
* ä»£ç : `model = LinearRegression()`
* *æ¯”å–»: å»äººæ‰å¸‚åœºé›‡ä½£äº†ä¸€ä¸ªä»€ä¹ˆéƒ½æ²¡å­¦çš„â€œæ–°å‘˜å·¥â€ã€‚*


2. **è®­ç»ƒ (Fit):** å–‚ç»™å®ƒæ•°æ®ï¼Œè®©å®ƒæ‰¾è§„å¾‹ã€‚
* ä»£ç : `model.fit(X, y)`
* *æ¯”å–»: è®©å‘˜å·¥å»â€œä¸Šå²—åŸ¹è®­â€ï¼Œç»™ä»–çœ‹å†å²è€ƒé¢˜ () å’Œç­”æ¡ˆ ()ã€‚*


3. **é¢„æµ‹ (Predict):** ç”¨å®ƒæ¥å¤„ç†æ–°æ•°æ®ã€‚
* ä»£ç : `model.predict(X_new)`
* *æ¯”å–»: å‘˜å·¥æ­£å¼å¹²æ´»ï¼Œå¤„ç†æ–°æ¥çš„ä¸šåŠ¡ã€‚*



---

## 6.2 å®æˆ˜æ¡ˆä¾‹ï¼šé¢„æµ‹æˆ¿ä»· (Linear Regression)

> **ğŸ¯ ä»»åŠ¡ç›®æ ‡:**
> æ—¢ç„¶æˆ‘ä»¬æ˜¯å…¥é—¨ï¼Œå°±ä»æœ€ç»å…¸çš„â€œçº¿æ€§å›å½’â€å¼€å§‹ã€‚
> æˆ‘ä»¬æœ‰ä¸€ç»„æˆ¿å±‹æ•°æ®ï¼ˆé¢ç§¯ vs ä»·æ ¼ï¼‰ï¼Œæˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ª AIï¼Œè®©å®ƒå‘Šè¯‰æˆ‘ï¼š**ä¸€å¥— 130 å¹³ç±³çš„æˆ¿å­ï¼Œå¤§æ¦‚èƒ½å–å¤šå°‘é’±ï¼Ÿ**

### ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡â€œå¹²å‡€â€çš„æ•°æ®

æˆ‘ä»¬å…ˆç”¨ Pandas å’Œ NumPy æ¨¡æ‹Ÿä¸€ä»½æ•°æ®ã€‚

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 1. æ¨¡æ‹Ÿæ•°æ® (åœ¨çœŸå®é¡¹ç›®ä¸­ï¼Œè¿™é‡Œæ˜¯ pd.read_csv)
# ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç”Ÿæˆ 50 ä¸ªæ ·æœ¬
np.random.seed(42) # å›ºå®šéšæœºç§å­ï¼Œä¿è¯ä½ è·‘å‡ºæ¥çš„ç»“æœå’Œæˆ‘ä¸€æ ·
areas = np.linspace(50, 200, 50) # é¢ç§¯: 50å¹³ç±³ åˆ° 200å¹³ç±³

# ä»·æ ¼ = é¢ç§¯*3.5 + åº•ä»·10ä¸‡ + å™ªå£°(40ä¸‡ä»¥å†…çš„æ³¢åŠ¨)
prices = areas * 3.5 + 10 + np.random.normal(0, 40, 50) 

# 2. å°è£…æˆ DataFrame
df = pd.DataFrame({
    'é¢ç§¯': areas,
    'ä»·æ ¼': prices
})

# 3. çœ‹ä¸€çœ¼æ•°æ®
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x='é¢ç§¯', y='ä»·æ ¼')
plt.title("æˆ¿ä»·åˆ†å¸ƒå›¾")
plt.show()

```

### ç¬¬äºŒæ­¥ï¼šç‰¹å¾ (X) ä¸ æ ‡ç­¾ (y) çš„åˆ†ç¦»

è¿™æ˜¯åˆå­¦è€…æœ€å®¹æ˜“æŠ¥é”™çš„åœ°æ–¹ã€‚Scikit-Learn å¯¹æ•°æ®çš„å½¢çŠ¶æœ‰ä¸¥æ ¼çš„**æ•°å­¦çº¦å®š**ï¼š

* **X (ç‰¹å¾/é¢˜ç›®):** å¿…é¡»æ˜¯ **äºŒç»´çŸ©é˜µ (2D Matrix)**ã€‚å“ªæ€•åªæœ‰ä¸€ä¸ªç‰¹å¾ï¼ˆé¢ç§¯ï¼‰ï¼Œå®ƒä¹Ÿå¾—æ˜¯ `50è¡Œ x 1åˆ—` çš„çŸ©é˜µã€‚**å˜é‡åé€šå¸¸å¤§å†™**ã€‚
* **y (æ ‡ç­¾/ç­”æ¡ˆ):** é€šå¸¸æ˜¯ **ä¸€ç»´å‘é‡ (1D Vector)**ã€‚**å˜é‡åé€šå¸¸å°å†™**ã€‚

```python
# å‡†å¤‡ X (ç‰¹å¾)
# .values æŠŠ DataFrame å˜æˆ NumPy æ•°ç»„
# .reshape(-1, 1) æŠŠå®ƒå¼ºè¡Œå˜æˆ (50, 1) çš„äºŒç»´çŸ©é˜µï¼å¦‚æœä¸åŠ è¿™ä¸€æ­¥ä¼šæŠ¥é”™ï¼
X = df['é¢ç§¯'].values.reshape(-1, 1) 

# å‡†å¤‡ y (æ ‡ç­¾)
y = df['ä»·æ ¼'].values

print(f"X shape: {X.shape}") # å¿…é¡»æ˜¯ (50, 1)
print(f"y shape: {y.shape}") # å¿…é¡»æ˜¯ (50,)

```

### ç¬¬ä¸‰æ­¥ï¼šæœ€é‡è¦çš„æ¦‚å¿µ â€”â€” è®­ç»ƒé›†ä¸æµ‹è¯•é›†æ‹†åˆ†

**ä¸ºä»€ä¹ˆä¸èƒ½æŠŠæ‰€æœ‰æ•°æ®éƒ½æ‹¿æ¥è®­ç»ƒï¼Ÿ**
è¿™å°±å¥½æ¯”è€å¸ˆè€ƒè¯•ã€‚å¦‚æœä½ æŠŠæœŸæœ«è€ƒè¯•çš„**åŸé¢˜å’Œç­”æ¡ˆ**éƒ½ç»™å­¦ç”ŸèƒŒï¼ˆå…¨é‡è®­ç»ƒï¼‰ï¼Œå­¦ç”Ÿå¯èƒ½è€ƒ 100 åˆ†ï¼Œä½†ä»–å¹¶æ²¡æœ‰å­¦ä¼šè§£é¢˜ï¼Œåªæ˜¯è®°ä½äº†ç­”æ¡ˆã€‚è¿™å«**è¿‡æ‹Ÿåˆ (Overfitting)**ã€‚

æˆ‘ä»¬éœ€è¦æŠŠæ•°æ®åˆ‡æˆä¸¤å—ï¼š

* **è®­ç»ƒé›† (Training Set):** 80% çš„æ•°æ®ã€‚ç”¨æ¥åšè¯¾åä½œä¸šï¼Œè®©æ¨¡å‹å­¦ä¹ ã€‚
* **æµ‹è¯•é›† (Test Set):** 20% çš„æ•°æ®ã€‚ç”¨æ¥åšæœŸæœ«è€ƒè¯•ï¼Œ**æ¨¡å‹åœ¨è®­ç»ƒæ—¶ç»å¯¹ä¸èƒ½çœ‹**ã€‚

```python
from sklearn.model_selection import train_test_split

# è‡ªåŠ¨æ‹†åˆ†æ•°æ®
# test_size=0.2 ä»£è¡¨ 20% åšæµ‹è¯•é›†
# random_state=42 ä¿è¯æ¯æ¬¡åˆ‡åˆ†çš„ç»“æœä¸€æ ·
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"è®­ç»ƒé›†æ•°é‡: {len(X_train)} | æµ‹è¯•é›†æ•°é‡: {len(X_test)}")

```

### ç¬¬å››æ­¥ï¼šä¸‰è¡Œä»£ç è®­ç»ƒæ¨¡å‹

è§è¯å¥‡è¿¹çš„æ—¶åˆ»åˆ°äº†ã€‚è™½ç„¶çº¿æ€§å›å½’èƒŒåçš„æ•°å­¦åŸç†ï¼ˆæœ€å°äºŒä¹˜æ³•ï¼‰æ¶‰åŠçŸ©é˜µæ±‚å¯¼ï¼Œä½†ç”¨ Scikit-Learn åªéœ€è¦ä¸‰è¡Œã€‚

```python
from sklearn.linear_model import LinearRegression

# 1. å®ä¾‹åŒ– (é›‡ä½£å‘˜å·¥)
model = LinearRegression()

# 2. è®­ç»ƒ (ä¸Šå²—åŸ¹è®­)
# âš ï¸ æ³¨æ„ï¼šæˆ‘ä»¬åªæŠŠâ€œè®­ç»ƒé›†â€å–‚ç»™å®ƒï¼åƒä¸‡åˆ«è®©å®ƒå·çœ‹æµ‹è¯•é›†ï¼
model.fit(X_train, y_train)

# 3. çœ‹çœ‹å®ƒå­¦åˆ°äº†ä»€ä¹ˆ
# çº¿æ€§å›å½’å…¬å¼: y = w * x + b
print(f"å­¦åˆ°çš„æƒé‡ (w): {model.coef_[0]:.2f}") 
print(f"å­¦åˆ°çš„æˆªè· (b): {model.intercept_:.2f}")

# çœŸå®çš„ w æ˜¯ 3.5ï¼Œçœ‹çœ‹æ¨¡å‹ç®—å‡ºæ¥çš„æ¥è¿‘å—ï¼Ÿ

```

### ç¬¬äº”æ­¥ï¼šæ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–

æ¨¡å‹è®­ç»ƒå¥½äº†ï¼Œå®ƒåˆ°åº•å‡†ä¸å‡†ï¼Ÿæˆ‘ä»¬è¦è®©å®ƒåœ¨â€œæµ‹è¯•é›†â€ä¸Šåšä¸€æ¬¡æœŸæœ«è€ƒè¯•ã€‚

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error

# 1. é¢„æµ‹ (è®©æ¨¡å‹åšæµ‹è¯•å·)
# æˆ‘ä»¬ç»™å®ƒ X_testï¼Œè®©å®ƒçŒœ y_pred
y_pred = model.predict(X_test)

# 2. è¯„ä¼° (è€å¸ˆæ”¹å·å­)
# MAE: å¹³å‡ç»å¯¹è¯¯å·® (é¢„æµ‹å€¼å’ŒçœŸå®å€¼å¹³å‡å·®äº†å¤šå°‘é’±)
mae = mean_absolute_error(y_test, y_pred)
print(f"å¹³å‡è¯¯å·® (MAE): {mae:.2f} ä¸‡")

# 3. å¯è§†åŒ–ï¼šç”»å‡ºé‚£æ¡å›å½’çº¿
plt.figure(figsize=(8, 5))
# ç”»æ•£ç‚¹ (çœŸå®æ•°æ®)
plt.scatter(X_test, y_test, color='blue', label='Real Price')
# ç”»çº¿ (é¢„æµ‹ç»“æœ)
plt.plot(X_test, y_pred, color='red', linewidth=3, label='Prediction Line')

plt.title("çº¿æ€§å›å½’é¢„æµ‹ç»“æœ")
plt.xlabel("é¢ç§¯")
plt.ylabel("ä»·æ ¼")
plt.legend()
plt.show()

```

**ğŸ§ æ€ä¹ˆçœ‹è¿™å¼ å›¾ï¼Ÿ**

* çº¢çº¿æ˜¯æ¨¡å‹è®¤ä¸ºçš„â€œæˆ¿ä»·è§„å¾‹â€ã€‚
* è“ç‚¹æ˜¯çœŸå®çš„æˆ¿ä»·ã€‚
* çº¢çº¿ç¦»è“ç‚¹è¶Šè¿‘ï¼Œè¯´æ˜æ¨¡å‹è¶Šå‡†ã€‚

---

## 6.3 ä¸¾ä¸€åä¸‰ï¼šå¦‚æœæˆ‘æƒ³æ¢ä¸ªæ¨¡å‹ï¼Ÿ

å‡å¦‚æˆ‘è§‰å¾—çº¿æ€§å›å½’å¤ªç®€å•äº†ï¼Œæˆ‘æƒ³ç”¨é«˜å¤§ä¸Šçš„**â€œå†³ç­–æ ‘ (Decision Tree)â€**æˆ–è€…**â€œéšæœºæ£®æ— (Random Forest)â€**ï¼Œä»£ç éœ€è¦é‡å†™å—ï¼Ÿ

**å®Œå…¨ä¸éœ€è¦ï¼** è¿™å°±æ˜¯ sklearn çš„é­…åŠ›ã€‚ä½ åªéœ€è¦æ”¹åŠ¨**ç¬¬ä¸€è¡Œ**ï¼ˆå®ä¾‹åŒ–ï¼‰çš„ä»£ç ï¼š

```python
# åªè¦æ”¹è¿™é‡Œï¼
# from sklearn.linear_model import LinearRegression
# model = LinearRegression()

# å˜æˆå†³ç­–æ ‘å›å½’ï¼š
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor() # æ¢ä¸ªå‘˜å·¥

# ä¸‹é¢çš„ä»£ç ä¸€å­—ä¸ç”¨æ”¹ï¼
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

```

---

## æœ¬ç« å°ç»“

æ­å–œä½ ï¼ä½ å·²ç»è·‘é€šäº†æœºå™¨å­¦ä¹ çš„**å…¨æµç¨‹ (Pipeline)**ï¼š

1. **å‡†å¤‡æ•°æ®:** æå®š  (çŸ©é˜µ) å’Œ  (å‘é‡)ã€‚
2. **æ‹†åˆ†:** `train_test_split` åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚
3. **è®­ç»ƒ:** `fit()`ã€‚
4. **é¢„æµ‹:** `predict()`ã€‚

**ä¸‹ä¸€ç« é¢„å‘Šï¼š**
ç°åœ¨çš„æ¨¡å‹åªèƒ½å¤„ç†â€œé¢ç§¯â€è¿™ä¸€ä¸ªæ•°å­—ã€‚ä½†å¦‚æœæœ‰â€œæˆ¿å±‹æœå‘â€ï¼ˆä¸œå—è¥¿åŒ—ï¼‰è¿™ç§**æ–‡å­—ç‰¹å¾**æ€ä¹ˆåŠï¼Ÿæ¨¡å‹ä¸è®¤è¯†æ±‰å­—å•Šã€‚
åœ¨ **ç¬¬ 7 ç« **ï¼Œæˆ‘ä»¬å°†å­¦ä¹  **ç‰¹å¾å·¥ç¨‹ (Feature Engineering)**ï¼Œå­¦ä¹ å¦‚ä½•æŠŠæ–‡æœ¬ã€ç±»åˆ«æ ‡ç­¾è½¬åŒ–ä¸ºæ•°å­—ï¼Œä¹Ÿå°±æ˜¯å¤§åé¼é¼çš„ **One-Hot ç¼–ç **ã€‚